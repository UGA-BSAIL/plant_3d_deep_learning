--------------------------------------------------------------------------
A process has executed an operation involving a call to the
"fork()" system call to create a child process.  Open MPI is currently
operating in a condition that could result in memory corruption or
other system errors; your job may hang, crash, or produce silent
data corruption.  The use of fork() (or system() or other calls that
create child processes) is strongly discouraged.

The process that invoked fork was:

  Local host:          [[7920,1],0] (PID 100797)

If you are *absolutely sure* that your application will successfully
and correctly survive a call to fork(), you may disable this warning
by setting the mpi_warn_on_fork MCA parameter to 0.
--------------------------------------------------------------------------
==> loading configs from ['configs/shapenet/pvcnn/c1.py']
/apps/eb/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/utils/cpp_extension.py:252: UserWarning: 

                               !! WARNING !!

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Your compiler (c++) is not compatible with the compiler Pytorch was
built with for this platform, which is g++ on linux. Please
use g++ to to compile your extension. Alternatively, you may
compile PyTorch from source using c++, and then you can also use
c++ to compile your extension.

See https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md for help
with compiling PyTorch from source.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

                              !! WARNING !!

  platform=sys.platform))
2022-09-11 15:38:06.357803: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
[seed] = 1588147245
[deterministic] = False
[data]
  [num_workers] = 16
  [num_classes] = 3
  [num_shapes] = 1
[dataset]
  [func] = <class 'datasets.shapenet.ShapeNet'>
  [root] = /scratch/fs47816/point_cloud_data/shapenetcore_partanno_segmentation_benchmark_v0_normal
  [with_normal] = False
  [with_one_hot_shape_id] = True
  [normalize] = True
  [jitter] = False
  [num_points] = 100000
[evaluate] = None
[train]
  [num_epochs] = 200
  [batch_size] = 1
  [meters]
    [acc/iou_{}]
      [func] = <class 'meters.shapenet.MeterShapeNet'>
      [num_classes] = 3
  [metric] = acc/iou_test
  [criterion]
    [func] = <class 'torch.nn.modules.loss.CrossEntropyLoss'>
  [optimizer]
    [func] = <class 'torch.optim.adam.Adam'>
    [lr] = 0.001
  [scheduler]
    [func] = <class 'torch.optim.lr_scheduler.CosineAnnealingLR'>
    [T_max] = 200
  [save_path] = runs/shapenet.pvcnn.c1
  [metrics] = ['acc/iou_test']
  [checkpoint_path] = runs/shapenet.pvcnn.c1/latest.pth.tar
  [checkpoints_path] = runs/shapenet.pvcnn.c1/latest/e{}.pth.tar
  [best_checkpoint_path] = runs/shapenet.pvcnn.c1/best.pth.tar
  [best_checkpoint_paths] = {'acc/iou_test': 'runs/shapenet.pvcnn.c1/best/best.acc.iou_test.pth.tar'}
[model]
  [func] = <class 'models.shapenet.pvcnn.PVCNN'>
  [num_classes] = 3
  [num_shapes] = 1
  [extra_feature_channels] = 0
[device] = cuda
[device_ids] = [0]

==> loading dataset "[func] = <class 'datasets.shapenet.ShapeNet'>
[root] = /scratch/fs47816/point_cloud_data/shapenetcore_partanno_segmentation_benchmark_v0_normal
[with_normal] = False
[with_one_hot_shape_id] = True
[normalize] = True
[jitter] = False
[num_points] = 100000"

==> creating model "[func] = <class 'models.shapenet.pvcnn.PVCNN'>
[num_classes] = 3
[num_shapes] = 1
[extra_feature_channels] = 0"
==> creating scheduler "[func] = <class 'torch.optim.lr_scheduler.CosineAnnealingLR'>
[T_max] = 200
[last_epoch] = -1"

==> training epoch 0/200
train:   0% 0/21 [00:00<?, ?it/s]train:   0% 0/21 [00:24<?, ?it/s]
Traceback (most recent call last):
  File "train.py", line 270, in <module>
    main()
  File "train.py", line 232, in main
    current_step=current_step, writer=writer)
  File "train.py", line 116, in train
    outputs = model(inputs)
  File "/apps/eb/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/apps/eb/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 153, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/apps/eb/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/scratch/fs47816/workdir/sample_scripts/pvcnn_s/pvcnn/models/shapenet/pvcnn.py", line 108, in forward
    features, _ = self.point_features[i]((features, coords))
  File "/apps/eb/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/scratch/fs47816/workdir/sample_scripts/pvcnn_s/pvcnn/modules/pvconv.py", line 36, in forward
    voxel_features = self.voxel_layers(voxel_features)
  File "/apps/eb/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/apps/eb/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/apps/eb/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/apps/eb/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 567, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 15.78 GiB total capacity; 13.94 GiB already allocated; 453.50 MiB free; 14.12 GiB reserved in total by PyTorch)
